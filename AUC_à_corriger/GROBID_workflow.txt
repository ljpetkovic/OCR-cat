* lancer l'image docker stable

docker pull medkhem/grobid-dictionaries-stable



* lancer l'image docker (avec l'information typographique)
** il faut changer le chemin absolu

docker run -v /Volumes/LaCie/Toolkit/Mirror/OCRcat/GROBID_LAC_LAV/trainingData_LAC_LAV_typo/toyData:/grobid/grobid-dictionaries/resources -p 8080:8080 -it medkhem/grobid-dictionaries-stable bash



* git pull


* mvn clean install -DskipTests


* Génération des données d'entraînement

1. dictionary-segmentation

java -jar /grobid/grobid-dictionaries/target/grobid-dictionaries-0.5.4-SNAPSHOT.one-jar.jar -dIn resources/dataset/dictionary-segmentation/corpus/alto/ -isALTO -dOut resources -exe createTrainingDictionarySegmentation

mvn generate-resources -P train_dictionary_segmentation -e




2. dictionary-body-segmentation

java -jar /grobid/grobid-dictionaries/target/grobid-dictionaries-0.5.4-SNAPSHOT.one-jar.jar -dIn resources/dataset/dictionary-segmentation/corpus/alto/ -isALTO -dOut resources -exe createTrainingDictionaryBodySegmentation

mvn generate-resources -P train_dictionary_body_segmentation -e





3. lexical-entry

java -jar /grobid/grobid-dictionaries/target/grobid-dictionaries-0.5.4-SNAPSHOT.one-jar.jar -dIn resources/dataset/dictionary-segmentation/corpus/alto/ -isALTO -dOut resources -exe createTrainingLexicalEntry

mvn generate-resources -P train_lexicalEntries -e




4. form

java -jar /grobid/grobid-dictionaries/target/grobid-dictionaries-0.5.4-SNAPSHOT.one-jar.jar -dIn resources/dataset/dictionary-segmentation/corpus/alto/ -isALTO -dOut resources -exe createTrainingForm

mvn generate-resources -P train_form -e



5. 

java -jar /grobid/grobid-dictionaries/target/grobid-dictionaries-0.5.4-SNAPSHOT.one-jar.jar -dIn resources/dataset/dictionary-segmentation/corpus/alto/ -isALTO -dOut resources -exe createTrainingSense





* Lancer les entraînements

** Dictionary Segmentation (pour les pages)

mvn generate-resources -P train_dictionary_segmentation -e


** Dictionary Body Segmentation (pour les entrées)

mvn generate-resources -P train_dictionary_body_segmentation -e


** Lexical Entry (pour les sous-entrées)

mvn generate-resources -P train_lexicalEntries -e


** Form (pour la première sous-entrée)

mvn generate-resources -P train_form -e


** Sense (pour la seconde sous-entrée)

mvn generate-resources -P train_sense -e


